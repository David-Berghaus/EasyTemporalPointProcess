data_config:
  train_dir: easytpp/amazon
  valid_dir: easytpp/amazon
  test_dir: easytpp/amazon
  data_format: json
  data_specs:
    num_event_types: 16
    pad_token_id: 16
    padding_side: right
    truncation_side: right
    padding_strategy: null
    truncation_strategy: null
    max_len: 96
    fim_context_size: 32
    fim_inference_size: 32
    fim_max_num_events: 96
    fim_sampling_strategy: sequential
    fim_episodes_per_epoch: 30
base_config:
  stage: train
  backend: torch
  dataset_id: amazon
  runner_id: std_tpp
  model_id: THP
  base_dir: ./checkpoints/
  specs:
    log_folder: ./checkpoints/1615644_130021120017152_251219-153700
    saved_model_dir: ./checkpoints/1615644_130021120017152_251219-153700/models/saved_model
    saved_log_dir: ./checkpoints/1615644_130021120017152_251219-153700/log
    output_config_dir: ./checkpoints/1615644_130021120017152_251219-153700/THP_train_amazon_output.yaml
model_config:
  rnn_type: LSTM
  hidden_size: 32
  time_emb_size: 16
  num_layers: 2
  sharing_param_layer: false
  loss_integral_num_sample_per_step: 20
  dropout_rate: 0.0
  use_ln: false
  thinning:
    num_seq: 10
    num_sample: 1
    num_exp: 200
    look_ahead_time: 5
    patience_counter: 3
    over_sample_rate: 5
    num_samples_boundary: 5
    dtime_max: 5
    num_step_gen: 1
  num_event_types_pad: 17
  num_event_types: 16
  event_pad_index: 16
  model_id: THP
  pretrained_model_dir: null
  gpu: 0
  model_specs: {}
trainer_config:
  seed: 42
  gpu: 0
  batch_size: 16
  max_epoch: 3
  shuffle: false
  optimizer: adam
  learning_rate: 0.001
  valid_freq: 1
  use_tfb: false
  metrics:
  - acc
  - rmse
